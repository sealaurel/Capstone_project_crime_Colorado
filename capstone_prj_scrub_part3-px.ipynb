{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Name: Author Name\n",
    "* Email:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENTS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **[Introduction](#INTRODUCTION)<br>**\n",
    "- **[OBTAIN](#OBTAIN)**<br>\n",
    "- **[SCRUB](#SCRUB)**<br>\n",
    "- **[EXPLORE](#EXPLORE)**<br>\n",
    "- **[MODEL](#MODEL)**<br>\n",
    "- **[iNTERPRET](#iNTERPRET)**<br>\n",
    "- **[Conclusions/Recommendations](#CONCLUSIONS-&-RECOMMENDATIONS)<br>**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Explain the point of your project and what question you are trying to answer with your modeling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you are running this notebook without restarting the kernel replace '%load_ext autoreload' in imports with '%reload_ext autoreload'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:31.812477Z",
     "start_time": "2021-07-16T18:23:29.447198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import statsmodels\n",
    "import statsmodels.tsa.api as tsa\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import math\n",
    "from math import sqrt\n",
    "import holidays\n",
    "import pmdarima as pm\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pmdarima.arima.stationarity  import ADFTest\n",
    "from pmdarima.arima.utils import ndiffs\n",
    "from pmdarima.arima.utils import nsdiffs\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "from functions_all import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data source and data description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T22:51:09.955934Z",
     "start_time": "2021-06-29T22:51:09.915935Z"
    }
   },
   "source": [
    "Data is from FBI Crime Data Explorer\n",
    "[NIBRS data for Colorado from 2009-2019](https://crime-data-explorer.fr.cloud.gov/pages/downloads)\n",
    "\n",
    "The [data dictionary](data/NIBRS_DataDictionary.pdf) is  and a [record descriptiopn](data/NIBRS_Record_Description.pdf) are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T22:49:22.256999Z",
     "start_time": "2021-06-29T22:49:22.003934Z"
    }
   },
   "source": [
    "The description of the main and reference tables is in data/README.md file.\n",
    "The agency implemented some changes to the files structure in 2016 and removed the sqlite create and load scripts from the zip directories.\n",
    "Another fact worth mentioning is that files 'nibrs_property_desc.csv' from 2014 and 2015 have duplicated nibrs_property_desc_ids (unique identifier in the nibrs_property_desc table) which complicated the loading of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the original data description is in description is in the [notebook](capstone_prj_scrub_part1.ipynb) with the first part of data pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an already created sqlite database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook with database creation is [here](creating_sqlite_db.ipynb). The referenced database is in ***data/sqlite/db/production1 db***. It takes 2.5 minutes to run the database creation script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I, pre-processing the data in SQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T17:53:54.389957Z",
     "start_time": "2021-07-07T17:53:54.374954Z"
    }
   },
   "source": [
    "The first part of the scrubbing process (working with sqlite3 database, production1) is in [this notebook](capstone_prj_scrub_part1.ipynb). It takes about 12 minutes to run the code in part1 notebook. The following code is using dataframes created in part I."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part I the following dataframes have been created and saved in the pickle files:<br>\n",
    "\n",
    "    1. df_incident: data/pickled_dataframes/incident.pickle; main incident DF with date/time of an incident\n",
    "    2. df_offense: data/pickled_dataframes/offense.pickle: main offense DF with offense names and categories\n",
    "    3. df_offender: data/pickled_dataframes/offender.pickle; main offender DF with demographic info\n",
    "    4. df_victim: data/pickled_dataframes/victim.pickle; main victim DF with demographic info\n",
    "    5. df_weapon: data/pickled_dataframes/weapon.pickle; main weapon DF with a weapon category used in an offense\n",
    "    6. df_bias: data/pickled_dataframes/bias.pickle; main bias DF with offense bias motivation\n",
    "    7. df_rel: data/pickled_dataframes/relationship.pickle; main victim-offender relationship DF with relationship category\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II, scrubbing the data in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><span style=\"font-size:1.2em;\">The next step is uploading, displaying info and scrubbing the dataframes in [part 2 notebook](capstone_prj_scrub_part2-px.ipynb) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><span style=\"font-size:1.2em;\"><b>1. Offense, incident, bias and weapon DataFrames are combined into one for the Times-series analysis<br>\n",
    "2. Offender, victim and relationship DataFrames are set aside for the future dashboard.</b></span><br><br>\n",
    "<span style=\"font-size:1.2em;\">The cleaned-up dataframes can be found here:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. df_incident: data/pickled_dataframes/incident_clean.pickle; main cleaned-up incident DF with date/time of an incident\n",
    "    2. df_offense: data/pickled_dataframes/offense_clean.pickle: main cleaned-up offense DF with offense names and categories\n",
    "    3. df_offender: data/pickled_dataframes/offender_clean.pickle; main cleaned-up offender DF with demographic info\n",
    "    4. df_victim: data/pickled_dataframes/victim_clean.pickle; main cleaned-up victim DF with demographic info\n",
    "    5. df_weapon: data/pickled_dataframes/weapon_clean.pickle; main cleaned-up weapon DF with a weapon category used in an offense\n",
    "    6. df_bias: data/pickled_dataframes/bias_clean.pickle; main cleaned-up bias DF with offense bias motivation\n",
    "    7. df_rel: data/pickled_dataframes/rel_clean.pickle; main cleaned-up victim-offender relationship DF with relationship category\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Incident, Offense, Bias and Weapon DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T21:25:05.601320Z",
     "start_time": "2021-07-12T21:25:05.588318Z"
    }
   },
   "source": [
    "<br><br><span style=\"font-size:1.2em;\">The cleaned-up FULL dataframes can be found here:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    df_full: 'data/pickled_dataframes/df_full_clean.pickle'; main cleaned-up combined DF for time-series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:34.764174Z",
     "start_time": "2021-07-16T18:23:31.813479Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/pickled_dataframes/df_full_clean.pickle', 'rb') as f:\n",
    "    df_full=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:05:21.833845Z",
     "start_time": "2021-07-08T14:05:21.611800Z"
    }
   },
   "source": [
    "# EXPLORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.2em; background: lightblue\">All EDA part is in the notebook with Part II [part 2 notebook](capstone_prj_scrub_part2-px.ipynb)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><span style=\"font-size:1.2em;\">The dictionaries with timeseries of varios crime categories and crime locations can be fount here:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. TS_crime_categoryt: data/pickled_ts_dict/TS_crime_category.pickle; a dictionary with crime categories and associated time series\n",
    "    2. TS_crime_against: data/pickled_ts_dict/TS_crime_against.pickle: a dictionary with crime against categories and associated time series\n",
    "    3. TS_crime_location: data/pickled_ts_dict/TS_crime_location.pickle; a dictionary with crime locations and associated time series\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into a training and a test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><span style=\"font-size:1.2em;\">I am cutting off a ~10% tail of my data to create a test set.</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:34.844192Z",
     "start_time": "2021-07-16T18:23:34.765175Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/pickled_ts/ts_weekly.pickle', 'rb') as f:\n",
    "    ts_weekly=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:35.145980Z",
     "start_time": "2021-07-16T18:23:34.845193Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = round(len(ts_weekly) * 0.90)\n",
    "ts_train, ts_test = ts_weekly[:train_size], ts_weekly[train_size:]\n",
    "print('Observations: %d weeks' % (len(ts_weekly)))\n",
    "print('Training Observations: %d weeks' % (len(ts_train)))\n",
    "print('Testing Observations: %d weeks' % (len(ts_test)))\n",
    "\n",
    "fig=display_figure_w_TSs(ts_train, ts_test, 'Training set', 'Test set', 'Training and Test Sets for Modeling')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Crime Rate Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:1.2em; background: lightblue\">All modeling of General Crime rate is in the notebook with Part II [part 2 notebook](capstone_prj_scrub_part2-px.ipynb)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Rate per Offense Category Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dictionaries with time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:35.225997Z",
     "start_time": "2021-07-16T18:23:35.146979Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/pickled_ts/TS_crime_category.pickle', 'rb') as f:\n",
    "    TS_crime_category=pickle.load(f)\n",
    "    \n",
    "with open('data/pickled_ts/TS_crime_against.pickle', 'rb') as f:\n",
    "    TS_crime_against=pickle.load(f)\n",
    "        \n",
    "with open('data/pickled_ts/TS_crime_location.pickle', 'rb') as f:\n",
    "    TS_crime_location=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the stationarity of the time-series in Offense category dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:39.574985Z",
     "start_time": "2021-07-16T18:23:35.226998Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_results1, ts_stationary1, ts_non_stationary_diff1=check_stationarity_multiple(TS_crime_category, window=52, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:39.671007Z",
     "start_time": "2021-07-16T18:23:39.575986Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><span style=\"font-size:1.2em; background:pink\">There are **12** time-series that are already stationary and **11** that are not and which require additional processing (differencing).</span><br><br>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differencing the time series that are not stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:41.684470Z",
     "start_time": "2021-07-16T18:23:39.673009Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_results2, ts_stationary2, ts_non_stationary_diff2=check_stationarity_multiple(ts_non_stationary_diff1, \n",
    "                                                                                  window=52, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:41.779826Z",
     "start_time": "2021-07-16T18:23:41.685470Z"
    }
   },
   "outputs": [],
   "source": [
    "df_results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><span style=\"font-size:1.2em; background:lightgreen\">All **11** time-series got stationarized by the first dfferencing </span><br><br>\n",
    "<span style=\"font-size:1.2em;\">Theere are two separate dictionaries for offenses categories: one with 12 original time-series, that were stationary from the get go and another one with 11 time-series that were pre-processed with the first differencing.</span><br><br>\n",
    "<span style=\"font-size:1.2em; background:lightblue\">The next step is to explore ACFs and PACFs of the timeframe and make a decision on the pdq and PDQs orders.</span><br><br>\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring ACFs and PACFs of the originally stationary time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:44.081857Z",
     "start_time": "2021-07-16T18:23:41.780827Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ACF_PACF_multiple(ts_stationary1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.221850Z",
     "start_time": "2021-07-16T18:23:44.082858Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ACF_PACF_multiple(ts_stationary2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto ARIMA for multiple categories of offenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.300370Z",
     "start_time": "2021-07-16T18:23:46.222850Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RESULTS = {}\n",
    "# for crime, ts  in  TS_crime_category.items():\n",
    "#     crime_categories_results = {}\n",
    "\n",
    "#     # Splittting it up\n",
    "#     print('==='*20)\n",
    "#     print('GRIDSEARCHING FOR {}'.format(crime)) \n",
    "#     train_size = round(len(ts) * 0.90)\n",
    "#     ts_train, ts_test = ts[:train_size], ts[train_size:]\n",
    "\n",
    "\n",
    "#     predictions_fig=display_figure_w_TSs(ts_train, ts_test, 'Training set', 'Test set', \n",
    "#                                              'Training and Test Sets for Modeling {}'.format(crime), limit_=False)\n",
    "\n",
    "\n",
    "#     #### Gridsearch\n",
    "\n",
    "#     auto_model_train = pm.auto_arima(ts_train,\n",
    "#                             start_p=0,start_q=0, d=1,\n",
    "#                             start_P=1, start_Q=1, D=1,\n",
    "#                             max_p=2, max_q=2,\n",
    "#                             max_P=2, max_Q=2,\n",
    "#                             m=52, maxiter=150,\n",
    "#                             trace=False,verbose=True)\n",
    "\n",
    "#     ## Fit SARIMAX with best parmas and compare forecast vs test\n",
    "#     best_model = tsa.SARIMAX(ts_train,order=auto_model_train.order,\n",
    "#                                 seasonal_order = auto_model_train.seasonal_order,\n",
    "#                                 enforce_invertibility=False).fit()\n",
    "\n",
    "#     ## Use diagnostics\n",
    "#     diagnostics(best_model)\n",
    "\n",
    "#     ## Prediction comparison\n",
    "#     plt.style.use('ggplot')\n",
    "#     y_hat_train=best_model.predict(typ='levels')\n",
    "#     y_hat_test=best_model.predict(start=ts_test.index[0], end=ts_test.index[-1], typ='levels')\n",
    "\n",
    "#     rmse = np.sqrt(mean_squared_error(ts_test, y_hat_test))\n",
    "#     print('RMSE of the {} model for {}'.format(crime, round(rmse,2)))\n",
    "\n",
    "\n",
    "#     predictions_fig=display_figure_w_TSs(ts_train, ts_test, 'Train set', 'Test set', \n",
    "#                              'Training and Test Sets Raw Values and Predictions, {}'.format(crime),\n",
    "#                               n=4, ts3=y_hat_test,\n",
    "#                               ts4=y_hat_train, label3='Prediction for Test set', label4='Prediction for Training set',\n",
    "#                                          limit_=False)      \n",
    "\n",
    "\n",
    "#     print('\\t-FINAL MODEL:')\n",
    "\n",
    "#     final_model = tsa.SARIMAX(ts,order=auto_model_train.order,\n",
    "#                         seasonal_order = auto_model_train.seasonal_order,\n",
    "#                         enforce_invertibility=False).fit()\n",
    "\n",
    "#     ## Plot forecast\n",
    "#     forecast_fig=plot_predictions(ts, final_model, 'Forecast For Two Years Forward, {}'.format(crime),\n",
    "#                                       steps=104, xmin='2015')\n",
    "\n",
    "#     ## Fill in results and\n",
    "#     crime_categories_results['final_model'] = final_model\n",
    "#     crime_categories_results['predict_fig'] = predictions_fig\n",
    "#     crime_categories_results['forecast_fig'] = forecast_fig\n",
    "\n",
    "#     ## Saving results to RESULTS dict\n",
    "#     RESULTS[crime] = crime_categories_results\n",
    "        \n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.380069Z",
     "start_time": "2021-07-16T18:23:46.301372Z"
    }
   },
   "outputs": [],
   "source": [
    "# cropped_RESULTS = {key:val for key, val in RESULTS.items() if ((key != 'Sex Offenses')&(key != 'Weapon Law Violations'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.459088Z",
     "start_time": "2021-07-16T18:23:46.381071Z"
    }
   },
   "outputs": [],
   "source": [
    "# cropped_RESULTS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.539106Z",
     "start_time": "2021-07-16T18:23:46.460088Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('data/pickled_models/RESULTS1.pickle', 'wb') as f:\n",
    "#     pickle.dump(cropped_RESULTS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.619125Z",
     "start_time": "2021-07-16T18:23:46.540106Z"
    }
   },
   "outputs": [],
   "source": [
    "# TS_crime_category_to_rerun1={}\n",
    "# TS_crime_category_to_rerun1['Sex Offenses']=TS_crime_category['Sex Offenses'].copy()\n",
    "\n",
    "# TS_crime_category_to_rerun1['Weapon Law Violations']=TS_crime_category['Weapon Law Violations'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.699152Z",
     "start_time": "2021-07-16T18:23:46.620125Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RESULTS_second_run = {}\n",
    "# for crime, ts  in  TS_crime_category_to_rerun1.items():\n",
    "#     crime_categories_results = {}\n",
    "\n",
    "#     # Splittting it up\n",
    "#     print('==='*20)\n",
    "#     print('GRIDSEARCHING FOR {}'.format(crime)) \n",
    "#     train_size = round(len(ts) * 0.90)\n",
    "#     ts_train, ts_test = ts[:train_size], ts[train_size:]\n",
    "\n",
    "\n",
    "#     predictions_fig=display_figure_w_TSs(ts_train, ts_test, 'Training set', 'Test set', \n",
    "#                                              'Training and Test Sets for Modeling {}'.format(crime), limit_=False)\n",
    "\n",
    "\n",
    "#     #### Gridsearch\n",
    "#     auto_model_train = pm.auto_arima(ts_train,\n",
    "#                             start_p=0,start_q=0, d=0,\n",
    "#                             start_P=0, start_Q=0, D=0,\n",
    "#                             max_p=2, max_q=2, max_d=1,\n",
    "#                             max_P=2, max_Q=2, max_D=1,\n",
    "#                             m=52, maxiter=300,\n",
    "#                             trace=False,verbose=True)\n",
    "     \n",
    "\n",
    "#     ## Fit SARIMAX with best parmas and compare forecast vs test\n",
    "#     best_model = tsa.SARIMAX(ts_train,order=auto_model_train.order,\n",
    "#                                 seasonal_order = auto_model_train.seasonal_order,\n",
    "#                                 enforce_invertibility=False).fit()\n",
    "\n",
    "\n",
    "#     ## Use diagnostics\n",
    "#     diagnostics(best_model)\n",
    "\n",
    "#     ## Prediction comparison\n",
    "#     plt.style.use('ggplot')\n",
    "#     y_hat_train=best_model.predict(typ='levels')\n",
    "#     y_hat_test=best_model.predict(start=ts_test.index[0], end=ts_test.index[-1], typ='levels')\n",
    "\n",
    "#     rmse = np.sqrt(mean_squared_error(ts_test, y_hat_test))\n",
    "#     print('RMSE of the {} model for {}'.format(crime, round(rmse,2)))\n",
    "\n",
    "\n",
    "#     predictions_fig=display_figure_w_TSs(ts_train, ts_test, 'Train set', 'Test set', \n",
    "#                              'Training and Test Sets Raw Values and Predictions, {}'.format(crime),\n",
    "#                               n=4, ts3=y_hat_test,\n",
    "#                               ts4=y_hat_train, label3='Prediction for Test set', \n",
    "#                                          label4='Prediction for Training set', limit_=False)      \n",
    "\n",
    "\n",
    "#     print('\\t-FINAL MODEL:')\n",
    "\n",
    "#     final_model = tsa.SARIMAX(ts,order=auto_model_train.order,\n",
    "#                         seasonal_order = auto_model_train.seasonal_order,\n",
    "#                         enforce_invertibility=False).fit()\n",
    "\n",
    "#     ## Plot forecast\n",
    "#     forecast_fig=plot_predictions(ts, final_model, 'Forecast For Two Years Forward, {}'.format(crime),\n",
    "#                                       steps=104, xmin='2015')\n",
    "\n",
    "#     ## Fill in results and\n",
    "#     crime_categories_results['final_model'] = final_model\n",
    "#     crime_categories_results['predict_fig'] = predictions_fig\n",
    "#     crime_categories_results['forecast_fig'] = forecast_fig\n",
    "\n",
    "#     ## Saving results to RESULTS dict\n",
    "#     RESULTS_second_run[crime] = crime_categories_results\n",
    "        \n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.779169Z",
     "start_time": "2021-07-16T18:23:46.700151Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('data/pickled_models/RESULTS2.pickle', 'wb') as f:\n",
    "#     pickle.dump(RESULTS_second_run, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:46.859187Z",
     "start_time": "2021-07-16T18:23:46.780170Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def print_out_models(dictionary):\n",
    "#     for crime, dict_ in dictionary.items():\n",
    "#         print('OFFENSE CATEGORY: '+ crime)\n",
    "#         for key, value in dict_.items():\n",
    "#             if key=='final_model':\n",
    "#                 print('\\nTHE FINAL MODEL SUMMARY: \\n')\n",
    "#                 display(value.summary());\n",
    "#                 display(value.plot_diagnostics(figsize=(15,7)));\n",
    "#             elif key=='predict_fig':\n",
    "#                 print('\\nPREDICTION FOR TRAIN AND TEST sets: \\n')\n",
    "#                 display(value);\n",
    "#             else:\n",
    "#                 print('\\nFORECAST: \\n')\n",
    "#                 display(value);\n",
    "#             plt.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:58.156113Z",
     "start_time": "2021-07-16T18:23:46.860188Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/pickled_models/RESULTS1.pickle', 'rb') as f:\n",
    "    results1_back=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:58.501675Z",
     "start_time": "2021-07-16T18:23:58.157113Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/pickled_models/RESULTS2.pickle', 'rb') as f:\n",
    "    results2_back=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:23:58.581526Z",
     "start_time": "2021-07-16T18:23:58.502675Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_results = {**results1_back, **results2_back}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T18:24:16.449572Z",
     "start_time": "2021-07-16T18:23:58.583526Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_out_models(combined_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iNTERPRET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSIONS & RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Summarize your conclusions and bullet-point your list of recommendations, which are based on your modeling results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO/FUTURE WORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "298.49px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
